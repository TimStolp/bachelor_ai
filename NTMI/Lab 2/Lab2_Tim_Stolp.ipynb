{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tim Stolp 11848782 ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**\n",
    "\n",
    "* [Probability Theory](#probability-theory)\n",
    "    * [Sample spaces and events](#sample-spaces-and-events)\n",
    "    * [Probability measure](#probability-measure) \n",
    "    * [Joint probability, conditional probability, and independence](#joint-conditional-independence)\n",
    "    * [Random variable](#random-variable)\n",
    "    * [Probability distribution](#probability-distribution)\n",
    "* [Important Distributions](#important-distributions)\n",
    "    * [Uniform distribution](#uniform)\n",
    "    * [Bernoulli distribution](#bernoulli)\n",
    "    * [Categorical distribution](#categorical)\n",
    "* [Representation and Maximum Likelihood Estimation](#representation)\n",
    "    \n",
    "    \n",
    "**Table of Exercises**\n",
    "\n",
    "* [Exercise 2-1](#ex2-1) (-/1)\n",
    "* [Exercise 2-2](#ex2-2) (-/3)\n",
    "* [Exercise 2-3](#ex2-3) (-/3)\n",
    "* [Exercise 2-4](#ex2-4) (-/1)\n",
    "* [Exercise 2-5](#ex2-5) (-/1)\n",
    "* [Exercise 2-6](#ex2-6) (-/1)\n",
    "* [Exercise 2-7](#ex2-7) (-/1)\n",
    "* [Exercise 2-8](#ex2-8) (-/1)\n",
    "* [Exercise 2-9](#ex2-9) (-/3)\n",
    "* [Exercise 2-10](#ex2-10) (-/8)\n",
    "\n",
    "\n",
    "**General notes**\n",
    "\n",
    "After completing this lab you should be able to \n",
    "\n",
    "* implement discrete probability distributions and estimate their parameters via maximum likelihood estimation\n",
    "* read and write mathematical notation\n",
    "\n",
    "Guidelines for notation\n",
    "\n",
    "* In this notebook you are expected to use $\\LaTeX$ for typesetting mathematical expressions, if you are not familiar with it check our own examples, they illustrate all commands you will need. If you need additional documentation try searching for it on Google, lots of people contribute answer to latex-related questions. A good starting point is [LaTeX/Mathematics](https://en.wikibooks.org/wiki/LaTeX/Mathematics) and for [equations](https://www.codecogs.com/latex/eqneditor.php).\n",
    "* I am very picky with notation, so make an effor to respect conventions and to typeset clear unambiguous mathematical expressions. For example, if I use $\\mathbb P$ to denote a measure, there is a reason for it, thus make sure to use `\\mathbb P` or you will not get the correct type of font. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"probability-theory\"> Probability Theory\n",
    "\n",
    "Here we provide a very *lightweight*, and rather *informal*, review of some concepts from probability theory and statistical estimation that are relevant to this course. For a more complete take on probability theory, and with a *proper formal treatment*, check this [excellent course](https://github.com/BasicProbability) out.\n",
    "\n",
    "Probability refers to a *subjective degree of confidence* (or *belief*) that an event of a certain nature will occur. For example, a weather report might say that there is a low probability of rain in the afternoon. In other words, the event of raining *might occur*. Probability theory deals with the formal foundations of how uncertainty can be quantified. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"sample-spaces-and-events\"> Sample spaces and events\n",
    "\n",
    "Probability theory is about assigning probability values to elements of a **sample space**. \n",
    "\n",
    "We use $\\Omega$ to denote the space, and $\\omega \\in \\Omega$ to denote members of that space. Members are usually  called **outcomes** or **samples**. \n",
    "\n",
    "Example of sample spaces:\n",
    "\n",
    "* in a toss coin the coin can land showing `heads` (H) or `tails` (T), thus $\\Omega = \\{H, T\\}$;\n",
    "* throwing a 6-sided die can yield an integer from 1 (included) to 6 (included), thus $\\Omega = \\{1,2,3,4,5,6\\}$\n",
    "* throwing a [10-sided die](https://en.wikipedia.org/wiki/Pentagonal_trapezohedron) followed by a 6-sided die yields pairs of numbers where the first number ranges from 1 (included) to 10 (included) and the second number ranges from 1 to 6, thus $\\Omega = \\{1, 2, 3, 4, 5, 6, 7, 8, 10\\} \\times \\{1, 2, 3, 4, 5, 6\\}$\n",
    "    * note that here we used a shortcut, the [cartesian product](https://en.wikipedia.org/wiki/Cartesian_product) denoted by $\\times$\n",
    "    * it's okay to use it, just keep in mind what it means: the cartesian product above is the set $\\{(1, 2), (1, 3), (1, 4), (1, 4), (1, 6), (2, 1), \\ldots, (10, 1), (10, 2), (10, 3), (10, 4), (10, 5), (10, 6) \\}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex2-1\" style=\"color:red\">**Exercise 2-1**</a> **[1 point]** What is the sample space associated with the [standard 52-playincard deck](https://en.wikipedia.org/wiki/Standard_52-card_deck)? Use $\\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit$ for the suits.\n",
    "\n",
    "$\\Omega = \\{A, 2, 3, 4, 5, 6, 7, 8, 10, Jack, Queen, King\\} \\times \\{\\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit\\}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a sample spaces we enumerate individual outcomes of some random experiment. However, we often care more about properties of these outcomes rather than the outcomes themselves. For example, we may be interested in whether the outcome of a die roll is an even number. We call that an **event**, where an event is any subset of the sample space. That is, if we use $A$ to denote the event, then $A \\subseteq \\Omega$.\n",
    "\n",
    "Example of events:\n",
    "\n",
    "* toss a coin and get heads: $\\{H\\}$;\n",
    "* roll a die and get 1: $\\{1\\}$;\n",
    "* roll a die and get an even number: $\\{2, 4, 6\\}$;\n",
    "* roll a die and get an even number bigger than 2: $\\{4, 6\\}$;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex2-2\" style=\"color:red\">**Exercise 2-2**</a> **[3 points]** Represent the following events for the 52-card sample space of [Exercise 2-1](#ex2-1)?\n",
    "\n",
    "1. pick an `A` of $\\diamondsuit$: $\\{A\\} \\times \\{\\diamondsuit\\}$\n",
    "2. pick an `A`: $\\diamondsuit$: $\\{A\\} \\times \\{\\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit\\}$\n",
    "3. pick a $\\diamondsuit$: $\\{A, 2, 3, 4, 5, 6, 7, 8, 10, Jack, Queen, King\\} \\times \\{\\diamondsuit\\}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define the notion of **event space**. There are some formal properties that event spaces must hold, we will not discuss them here. Instead we will always just assume that for a given sample space $\\Omega$, a convenient event space $\\mathcal A$ always exists. That 'convenient' event space typically is the *powerset* of the sample space, denoted $\\mathcal P(\\Omega)$. The [powerset](https://en.wikipedia.org/wiki/Power_set) of $\\Omega$ is the set of all subsets of $\\Omega$, which therefore includes the emptyset $\\emptyset$ and $\\Omega$ itself. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"probability-measure\"> Probability measure\n",
    "\n",
    "In mathematics, a *measure* is a function that maps elements from a set of sets (such as events in a event space) to real numbers and for which some formal properties hold. We will not survey measure theory, but we will pay particular attention to one important measure, namely, the **probability measure**.\n",
    "\n",
    "Let $(\\Omega, \\mathcal A)$ denote a sample space and an event space, and let $A \\in \\mathcal A$ denote an event, then a probability measure $\\mathbb P: \\mathcal A \\rightarrow \\mathbb R$ takes elements in the event space and maps them to a real number (a *probability value*) and is such that:\n",
    "\n",
    "\\begin{align}\n",
    "(1) \\quad\\quad &  \\mathbb P(A) \\ge 0  \\text{ for all } $A \\in \\mathcal A & \\\\\n",
    "(2) \\quad\\quad & \\mathbb P \\left( \\bigcup_{i=1}^k = \\sum_{i=1}^k \\mathbb P(A_i) \\right) & \\text{for disjoint events } A_1, A_2, \\ldots, A_k \\\\\n",
    "(3) \\quad\\quad & \\mathbb P(\\Omega) = 1 & \n",
    "\\end{align}\n",
    "\n",
    "Let's digest this. \n",
    "* Property (1) means that the smallest probability value atainable by any event is 0. \n",
    "* Property (2) means that the total probability assigned to $k$ [disjoint events](https://en.wikipedia.org/wiki/Disjoint_sets) is the sum of the probability values assigned to each of the $k$ events independently. \n",
    "* And finally, property (3) means that if we consider the event which is the set of all possible outcomes, we have a total probability value of 1. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's diggest this some more, this time with an example. Suppose we are throwing a dice. The sample space is $\\Omega = \\{1, 2, 3, 4, 5, 6\\}$. There are many events we can be interested in, for example:\n",
    "\n",
    "* `getting 1` represented by the set $\\{1\\}$;\n",
    "* `getting 2` represented by the set $\\{2\\}$;\n",
    "* `getting either 1 or 2` represented by the set $\\{1, 2\\}$\n",
    "* `getting an odd number` represented by the set $\\{1, 3, 5\\}$\n",
    "* `getting more than 2` represented by the set $\\{3, 4, 5, 6\\}$\n",
    "* `getting whatever` represented by the set $\\{1, 2, 3, 4, 5, 6\\}$ (note that this is exactly equivalent to the complete sample space $\\Omega$)\n",
    "\n",
    "There are so many things about this sample space that we may be interested in, that we just assume we may potentially be interested in any event in $\\mathcal P(\\Omega)$.\n",
    "\n",
    "* Property (1) implies that the smaller probability value assigned to any single event in the event space is 0.\n",
    "* Property (2) implies that if we take disjoint events such as $\\{1\\}$ (`getting 1`) and $\\{2\\}$ (`getting 2`), the total probability value assigned to the union is the sum of probability values, that is, $\\mathbb P(\\{1, 2\\}) = \\mathbb P(\\{1\\}) + \\mathbb P(\\{2\\})$.\n",
    "* Property (3) implies that the event $\\Omega$ (`whatever`) has probability 1. This is the famous informal rule that says *probabilities must add up to 1*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may not look obvious at first, but from properties 1 to 3 we can conclude that:\n",
    "\n",
    "\\begin{align}\n",
    "(4) \\quad\\quad & \\mathbb P(\\emptyset) = 0 & \\\\\n",
    "(5) \\quad\\quad & \\mathbb P(A \\cup B) = \\mathbb P(A) + \\mathbb P(B) - \\mathbb P(A \\cap B) & \\text{for events } A, B \\in \\mathcal A\\\\\n",
    "(6) \\quad\\quad & \\mathbb P(\\Omega \\setminus A) = 1 - \\mathbb P(A) & \\text{for an event } A \\in \\mathcal A\n",
    "\\end{align}\n",
    "\n",
    "Let's digest these ones now. \n",
    "\n",
    "* Property (4) states that the *empty event* has 0 probability: this is to say that if we observe a random experiment something will happen (there is no chance that nothing will happen).\n",
    "* Property (5) is a generalisation of property (2) which does not require *disjoint* events. Also, it generalises trivially to more than 2 events. \n",
    "* Property (6) is also called the *complement rule*. For example, the probability of `not getting 2` is $\\mathbb P(\\{1, 3, 4, 5, 6\\})$ which is the same as 1 minus the probability of `getting 2`, that is, $1 - \\mathbb P(\\{2\\})$.\n",
    "\n",
    "\n",
    "We now define the concept of a **probability space**. A probability space is a triple $(\\Omega, \\mathcal A, \\mathbb P)$ consisting of a sample space $\\Omega$, an event space $\\mathcal A$, and a probability measure $\\mathbb P$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex2-3\" style=\"color:red\">**Exercise 2-3**</a> **[3 points]** For the probability space $(\\Omega, \\mathcal P(\\Omega), \\mathbb P)$ where $\\Omega$ is the sample space of Exercise 2-1 (52-card deck), give an expression for the probability of picking a card that complies with the following cases (use the complement rule whenever possible and make sure you provide representations for every event present in the expression):\n",
    "\n",
    "1. Not an `A`: $\\mathbb P (\\{ \\Omega \\setminus A\\}) = 1 - \\mathbb P (\\{A\\})$\n",
    "2. Not a $\\heartsuit$: $\\mathbb P (\\{ \\Omega \\setminus \\heartsuit \\}) = 1 - \\mathbb P (\\{ \\heartsuit \\})$\n",
    "3. Neither an `A` nor a $\\heartsuit$: $\\mathbb P(\\{ \\Omega \\setminus A \\} \\cap \\mathbb P (\\{ \\Omega \\setminus\\heartsuit \\}) = (1 - \\mathbb P (\\{A\\})) \\times (1 - \\mathbb P (\\{ \\heartsuit \\})) = 1 - \\mathbb P (\\{A\\}) - \\mathbb P (\\{ \\heartsuit \\}) + \\mathbb P (\\{A \\cap \\heartsuit \\})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"joint-conditional-independence\"> Joint probability, conditional probability, and independence \n",
    "\n",
    "An important concept is that of **joint probability**, which concerns the probability of the intersection of events. We denote joint probability between two events $A, B$ by $\\mathbb P(A \\cap B)$ or equivalently $\\mathbb P(A, B)$ --- where the order of enumeration is arbitrary.\n",
    "\n",
    "We can find the joint probability by using the elementary properties above involving union and complements. For that we will need [De Morgan's law](https://en.wikipedia.org/wiki/De_Morgan's_laws).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex2-4\" style=\"color:red\">**Exercise 2-4**</a> **[1 point]** Give an expression for the joint probability $\\mathbb P(A \\cap B)$ in terms of union and complements by applying De Morgan's law. You may use one or more of the properties (1) to (6).\n",
    "\n",
    "$\\mathbb P(A \\cap B)$ = $1 - (\\mathbb P(\\Omega \\setminus A) \\cup \\mathbb P(\\Omega \\setminus B))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joint probability help us define the concept of **conditional probability**. The probability of an event $A$ conditioned on event $B$ having happened with $\\mathbb P(B) > 0$ is defined as: \n",
    "\n",
    "\\begin{equation}\n",
    "    (7) \\quad\\quad \\mathbb P(A|B) = \\frac{\\mathbb P(A \\cap B)}{\\mathbb P(B)}\n",
    "\\end{equation}\n",
    "\n",
    "The interpretation of conditional probabilities is that they are the probabilities of events assuming that another event has already occurred.\n",
    "\n",
    "If the occurence of event $A$ has no influence on event $B$ (and thus necessarily also vice verca) $A$ and $B$ are said to be **independent** events, denoted by $A \\perp B$. For independent events it holds that:\n",
    "\n",
    "\\begin{equation}\n",
    "    (8) \\quad\\quad \\mathbb P(A | B) = \\mathbb P(A)\n",
    "\\end{equation}\n",
    "\n",
    "With (7) and (8) we conclude that for *independent* events:\n",
    "\n",
    "\\begin{equation}\n",
    "    (9) \\quad\\quad \\mathbb P(A \\cap B) = \\mathbb P(A) \\times \\mathbb P(B)\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex2-5\" style=\"color:red\">**Exercise 2-5**</a> **[1 point]** Prove property (9) using property (7) and (8).\n",
    "\\begin{equation}\n",
    "    \\frac{\\mathbb P(A \\cap B)}{\\mathbb P(B)} = \\mathbb P(A)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{\\mathbb P(A \\cap B)}{\\mathbb P(B)} \\times \\mathbb P(B) = \\mathbb P(A) \\times \\mathbb P(B)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\quad\\quad \\mathbb P(A \\cap B) = \\mathbb P(A) \\times \\mathbb P(B)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"random-variable\"> Random variable\n",
    "\n",
    "In general, we perform random experiments to investigate particular properties of outcomes. \n",
    "We will consider an example from [Schulz and Schaffner (2016)](https://github.com/BasicProbability):\n",
    "\n",
    "\n",
    "> Like most people living in the north of Europe, your choice of clothing probably depends strongly on the weather. Let us assume that you have a thick winter jacket that you put on when it is cold, a light soft-shell jacket that you wear when temperatures are mild and that you simply wear a T-shirt or a sweater when it is warm. Let us also assume that the forecasting site you consult every morning reports the temperatures up to one decimal. The question is: does it matter to you whether it is 5.4 or 7.3 degrees centigrade outside when you make your decision about what to wear? Most likely you are only interested in whether it is cold, mild or warm. This may obviously vary according to your own perception of warmth and cold. Here we will assume that it is cold whenever the temperature is below 10 degrees, mild between 10 and 20 degrees (inclusive) and warm whenever the temperature rises above 20 degrees. So what you are really interested in, at least as far as clothing is concerned, is whether the temperature $t$ is $t < 10$ or $10 \\le t \\le 20$ or $t > 20$. What we are looking for is a way of transforming outcomes from the temperature scale into judgements of perceived temperature.\n",
    "\n",
    "\n",
    "A **random variable** $X$ on a probability space $(\\Omega, \\mathcal A, \\mathbb P)$ is a function $X: \\Omega \\rightarrow \\mathbb R$ that maps elements in the *sample space* to real numbers. Moreover we require that:\n",
    "\n",
    "(10) for all $r \\in \\mathbb R$, the set $A = \\{\\omega ~ |~ X(\\omega) \\leq r\\}$ is in the *event space* $\\mathcal A$\n",
    "* we read (10) as: $A$ is the set of all outcomes $\\omega \\in \\Omega$ which the function $X$ maps to a real number less or equal to $r$; and $A$ belongs to the event space, thus $A$ is an event;\n",
    "* the sample space is the *domain* of the random variable\n",
    "* the real line is the *co-domain* of the random variable \n",
    "* it's sometimes convenient to refer directly to the assignments that a random variable may take on, that is, the particular subset of real values that the random variable maps outcomes to (the *image* of the function). We call that set the random variable's **support** and we denote it by a caligraphic version of the letter used to denote the random variable itself. That is, we usually say:\n",
    "> a random variable $X$ takes on values in the set $\\mathcal X$\n",
    "\n",
    "By convention, we denote random variables with capital Roman letters such as $X$, $Y$, or $Z$.\n",
    "\n",
    "\n",
    "Example: let's define a random variable $X$ for the weather situation where temperature values $t$ are elements of our sample space.\n",
    "\n",
    "\\begin{equation}\n",
    "    X(t) = \n",
    "    \\begin{cases} \n",
    "      1 & t < 10 \\\\\n",
    "      2 & 10 \\le t \\le 20 \\\\\n",
    "      3 & t > 20\n",
    "    \\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "Note that even though the underlying sample space is not discrete, the random variable itself is because it buckets temperature values in 3 intervals. In other words its image is the finite set $\\mathcal X = \\{1, 2, 3\\}$. Also, note that we did not have to explicitly define a sample space, neither an event space (random variables are very handy!). \n",
    "\n",
    "**Assignment**: whenever a random variable $X$ takes on a particular value, we write $X=x$ using the corresponding lowercase letter as a generic value. This notation hides a lot of details, so let's look into it closely:\n",
    "* when we write an assignment $X=x$, we implicitly refer to the event $A = \\{\\omega ~| ~ X(\\omega) = x\\}$. Of course, all that respecting the conditions in (10), that is,  $\\omega \\in \\Omega$ and $A \\in \\mathcal A$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let us visualise the random variable X of the temperature example\n",
    "#  since RVs are functions, we can plot them\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot([-20, 9.99], [1, 1])\n",
    "plt.plot([10, 20], [2, 2])\n",
    "plt.plot([20.01, 50], [3, 3])\n",
    "plt.yticks([1, 2, 3], [1, 2, 3])\n",
    "plt.xlim(-20,50)\n",
    "plt.ylabel('X(t)')\n",
    "plt.xlabel('t (C)')\n",
    "_ = plt.legend(['cold', 'mild', 'warm'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex2-6\" style=\"color:red\">**Exercise 2-6**</a> **[1 point]** Define a random variable that models the number of heads when we toss two coins. Hint: in this case start by defining a sample space. \n",
    "\n",
    "$\\Omega = \\{(H,H), (H,T), (T,H), (T,T)\\}$\n",
    "\n",
    "\\begin{equation}\n",
    "    X(H) = \n",
    "    \\begin{cases} \n",
    "      2 & (H,H) \\\\\n",
    "      1 &  (H,T), (T,H)\\\\\n",
    "      0 & (T,T)\n",
    "    \\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "$A = \\{H ~| ~ X(H) = x\\}$ with $H \\in \\Omega$ and $A \\in \\mathcal A$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is in general the case that for a random variable of interest there are multiple equivalent ways to define it, starting from the fact that it all depends on how we define the sample space. That's why sometime it's easier to define the random variable directly and leave the sample space *implicitly defined*. \n",
    "\n",
    "Note that so far we have discussed random variables that can take on discrete values, i.e. one out of $k$ possibilities, where $k$ is some finite number. We call these **discrete random variables**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"probability-distribution\"> Probability distribution\n",
    "\n",
    "The **discrete probability distribution** of a random variable $X$ is denoted by $P_X$ and is defined as the function\n",
    "\n",
    "\\begin{equation}\n",
    "    (11) \\quad\\quad P_X(X=x) \\triangleq \\mathbb P(\\{\\omega ~ | ~ X(\\omega) = x\\})\n",
    "\\end{equation}\n",
    "\n",
    "It is not at all unusual to drop one or both mentions to $X$, thus denoting the probability value by $P_X(x)$, $P(X=x)$, or $P(x)$. We do that whenever there is no risk of ambiguity.\n",
    "\n",
    "We call **probability mass function** (or *pmf*) the function\n",
    "\\begin{equation}\n",
    "    f(a) = P_X(X=a)\n",
    "\\end{equation}\n",
    "it simply returns the probability value of associated with $X=a$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex2-7\" style=\"color:red\">**Exercise 2-7**</a> **[1 point]** If a discrete random variable $X$ takes on values in the set $\\mathcal X$, what's the result of the expression below and why?\n",
    "\n",
    "* $\\sum_{x \\in \\mathcal X} P_X(X=x)$\n",
    "\n",
    "Since $\\mathcal X$ contains all the possible values that $X$ can take and\n",
    "\n",
    "$\\sum_{x \\in \\mathcal X} P_X(X=x) = \\sum_{x \\in \\mathcal X} \\mathbb P(\\{\\omega ~ | ~ X(\\omega) = x\\})$\n",
    "\n",
    "So you have the sum of all probabilities of the values of $\\mathcal X$ which is always 1 (equation 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **cumulative distribution function** (or *cdf*) is used when we are interested in assessing the probability of a range of values.\n",
    "\n",
    "The cdf of a distribution $P_X$ of the random variable $X$ is the function\n",
    "\n",
    "\\begin{align}\n",
    "F(a) &\\triangleq P(X \\le a) \\\\\n",
    "       &=  \\sum_{x \\le a} P_X(x)\n",
    "\\end{align}\n",
    "\n",
    "it returns the cumulative probability over the interval $(-\\infty, a]$.\n",
    "\n",
    "Note that it is trivial then to obtain the probability of $X$ falling in the interval $[a, b]$, we just compute $F(b) - F(a)$ for $b \\ge a$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"important-distributions\"> Important Distributions\n",
    "\n",
    "Now we will illustrate some instances of discrete probability distributions\n",
    "\n",
    "## <a name=\"uniform\"> Uniform distribution\n",
    "\n",
    "The [Uniform distribution](https://en.wikipedia.org/wiki/Discrete_uniform_distribution) defined over $k$ outcomes is such that every outcome has the same probability. Because property (3) must always hold, it's obvious to see that each outcome has to have probability $\\frac{1}{k}$. We declare Uniform random variables as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "    X \\sim \\text{Uniform}(k)\n",
    "\\end{equation}\n",
    "\n",
    "This is the math equivalent to: $X$ follows a **Uniform distribution** with **parameter** $k$ (number of outcomes)\n",
    "* a uniform random variable takes on values in the set $\\{1, ..., k\\}$\n",
    "* we call $k$ a *parameter* of the distribution because it helps specify it\n",
    "* we immediately know that $P(x) = \\frac{1}{k}$ for $x \\in \\{1, ..., k\\}$\n",
    "* it's not difficult to generalise the uniform distribution to take on values in any finite discrete interval $\\{a, a + 1, \\ldots, a + k\\}$\n",
    "\n",
    "Here is a visualisation of a uniform distribution over $k=5$ possible outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "k = 5\n",
    "_ = plt.bar(np.arange(1, k + 1), np.ones(k) / k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"bernoulli\"> Bernoulli distribution\n",
    "\n",
    "The [Bernoulli distribution](https://en.wikipedia.org/wiki/Bernoulli_distribution) is defined over exactly 2 outcomes (a *binary* event). By convention we say that the outcome is either 1 (*True* or *positive class*) or 0 (*False* or *negative class*). We fully specify the Bernoulli distribution by specifying the probability of the positive class. Then by the complement rule (6) we know that $P_X(0) = 1 - P_X(1)$. We declare Bernoulli random variables as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "    X \\sim \\text{Bernoulli}(p)\n",
    "\\end{equation}\n",
    "\n",
    "This is the math equivalent to: $X$ follows a **Bernoulli distribution** with **parameter** $p$\n",
    "* a Bernoulli variable takes on values in the set $\\{0, 1\\}$\n",
    "* we call the probability of the positive class a *parameter* of the distribution because it helps specify it\n",
    "* the Bernoulli parameter is the probability of the positive class, and therefore, $0 \\le p \\le 1$ for it to be a valid distribution\n",
    "* we immediately know that $P_X(1) = p$ and $P_X(0) = 1 - p$\n",
    "\n",
    "Suppose a Bernoulli whose positive class probability is 0.7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p1 = 0.7\n",
    "plt.bar([0, 1], [1 - p1, p1])\n",
    "_ = plt.xticks([0, 1], ['False', 'True'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"categorical\"> Categorical distribution\n",
    "\n",
    "The [Categorical distribution](https://en.wikipedia.org/wiki/Categorical_distribution) defined over $k$ values can be used to represent the distribution of any discrete  random variable whose sample space is finite.  We declare  categorical random variables as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "    X \\sim \\text{Categorical}(\\theta_1, \\ldots, \\theta_k)\n",
    "\\end{equation}\n",
    "\n",
    "This is the math equivalent to: $X$ follows a **Categorical distribution** with **parameters** $\\langle \\theta_1, \\ldots, \\theta_k \\rangle$\n",
    "* a Categorical variable takes on values in the finite set $\\{1, \\ldots, k\\}$;\n",
    "* we call the parameters of the categorical distribution *class probabilities*, these are probabilities associated with each outcome and they help us specify the distribution;\n",
    "* we sometimes abreviate the parameters $\\langle \\theta_1, \\ldots, \\theta_k \\rangle$ into $\\pmb \\theta$ which we call a *parameter vector* (often we drop the word *vector* and call it simply a *parameter*);\n",
    "* this $k$-dimensional vector $\\pmb \\theta$ is no ordinary vector, each one of its $k$ values must be a probability value and therefore $0 \\le \\theta_x \\le 1$ for every assignment $x \\in \\{1, \\ldots, k\\}$; moreover, to make a valid distribution, they must also obey $\\sum_{x=1}^k \\theta_x = 1$; a parameter vector that complies with such conditions is also called a *probability vector*;\n",
    "* we immediately know that $P_X(x) = \\theta_x$.\n",
    "\n",
    "\n",
    "Let's illustrate this with an example. Suppose we have a bag with 10 marbles where 3 of them are blue, 2 of them are red, and 5 of them are white. Then the probability that the first ball drawn at random is:\n",
    "* blue is 3/10 or 0.3\n",
    "* red is 2/10 or 0.2\n",
    "* white is 5/10 or 0.5\n",
    "We can design a random variable that models the color of the first ball drawn at random from the bag:\n",
    "\n",
    "\\begin{equation}\n",
    "    X(\\omega) = \n",
    "    \\begin{cases} \n",
    "      1 & \\omega = \\text{blue} \\\\\n",
    "      2 & \\omega = \\text{red}\\\\\n",
    "      3 & \\omega = \\text{white}\n",
    "    \\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "where we arbitrarily decided to map from colors to numbers in lexicographic order (note that we have to realise this mapping because the random variable assignments should be integers from 1 to $k$ with $k=3$ in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This our sample space: we use a list (rather than a set) because we want it sorted\n",
    "sample_space = ['blue', 'red', 'white']\n",
    "# These are the values our random variable takes on \n",
    "rv_values = [1, 2, 3]\n",
    "# This is the mapping from sample space (colours) to numbers (assignments of X)\n",
    "rv_mapping = dict(zip(sample_space, rv_values))  # realises the mapping above\n",
    "# And these are the probabilities associated with each colour in the example\n",
    "probabilities = [0.3, 0.2, 0.5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample space: ['blue', 'red', 'white']\n",
      "Mapping function: {'blue': 1, 'red': 2, 'white': 3}\n",
      " outcome 'blue' mapped to 1 has probability 0.30\n",
      " outcome 'red' mapped to 2 has probability 0.20\n",
      " outcome 'white' mapped to 3 has probability 0.50\n"
     ]
    }
   ],
   "source": [
    "# Let's visualise what we accomplished\n",
    "print('Sample space:', sample_space)\n",
    "print('Mapping function:', rv_mapping)\n",
    "for omega in sample_space:\n",
    "    x = rv_mapping[omega]\n",
    "    theta_x = probabilities[x - 1]  # we subtract 1 because random access to lists in Python is 0-based\n",
    "    print(\" outcome %r mapped to %d has probability %.2f\" % (omega, x, theta_x))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can also plot our probability distribution, it's simply a bar plot\n",
    "#  each bar represents the probability of one of the classes\n",
    "plt.bar(rv_values, probabilities)\n",
    "# and we can label the ticks of the x-axis with the classes (colours) rather than the assignments (integers)\n",
    "_ = plt.xticks(rv_values, sample_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules of probability\n",
    "\n",
    "> From now on we will be a bit less formal about the whole sample space, event space, probability measure thing. We will specify our random variables by describing the sample space somewhat informally and we will assume an appropriate mapping exists. The point is that from now on we want to focus on manipulating probability distributions.\n",
    "\n",
    "A very important result of probability theory is called the **chain rule**\n",
    "\n",
    "\\begin{equation}\n",
    "(12) \\quad\\quad P(x, y) = P(x)P(y|x)\n",
    "\\end{equation}\n",
    "\n",
    "this rule relates the probability of the *joint assignment* $x$ and $y$ (left hand-side) to the *marginal* probability of $x$ (first term on the right-hand side), and the *conditional* probability of $y$ given $x$ (second probability on the rigth-hand side). \n",
    "\n",
    "This rule can be generalised to $n \\ge 2$ events and the particular order in which we enumerate them is arbitrary (the result does not depend on the order).\n",
    "\n",
    "\\begin{equation}\n",
    "(13) \\quad\\quad P(\\alpha_1, \\ldots, \\alpha_n) = P(\\alpha_1)\\prod_{i = 2}^n P(\\alpha_i|\\alpha_1, \\ldots, \\alpha_{i-1})\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "For a joint distribution over $X$ and $Y$, the **marginal probability** of an assignment $X=x$ is the result of considering the total probability associated with $X=x$ regardless of the assignment to $Y$:\n",
    "\n",
    "\\begin{equation}\n",
    "(14) \\quad\\quad P(X=x) = \\sum_{y} P(X=x, Y=y)\n",
    "\\end{equation}\n",
    "\n",
    "where the sum is over all values in the image of the random variable $Y$. \n",
    "\n",
    "\n",
    "Finally, another important rule shows us how to invert a conditional probability distribution, this is called the **Bayes rule**:\n",
    "\n",
    "\\begin{equation}\n",
    "(15) \\quad\\quad P(X=x|Y=y) = \\frac{P(Y=y|X=x)P(X=x)}{P(Y=y)}\n",
    "\\end{equation}\n",
    "\n",
    "This follows trivially from the definition of conditional probability and the chain rule. \n",
    "\n",
    "\n",
    "The next important concept to discuss is that of a random variable. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex2-8\" style=\"color:red\">**Exercise 2-8**</a> **[1 point]** Prove the *Bayes rule*\n",
    "\n",
    "\\begin{equation}\n",
    "    \\quad\\quad \\mathbb P(x|y) = \\frac{\\mathbb P(x \\cap y)}{\\mathbb P(y)}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\mathbb P(x \\cap y) = \\mathbb P(x)\\mathbb P(y|x)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\quad\\quad \\mathbb P(x|y) = \\frac{\\mathbb P(y|x)\\mathbb P(x)}{\\mathbb P(y)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"representation\"> Representation and Maximum Likelihood Estimation\n",
    "\n",
    "\n",
    "We can represent random variables in a computer by representing their distribution. Then we can *simulate/sample* values from that distribution. Here you will learn how to represent a Bernoulli variable and a Categorical variable as well as how to simulate them. \n",
    "\n",
    "Recall that a Bernoulli variables takes exactly 1 parameter to represent, whereas a Categorical over $k$ possible events, takes exactly $k$ values. \n",
    "\n",
    "\n",
    "**Bernoulli**: we will represent a bernoully variable by storing its Bernoulli parameter (a number between 0 and 1). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Bernoulli:\n",
    "    \n",
    "    def __init__(self, p):\n",
    "        \"\"\"\n",
    "            X ~ Bernoulli(p)\n",
    "            where p is the probability of the positive class\n",
    "        \"\"\"\n",
    "        if not (0 <= p <= 1):\n",
    "            raise ValueError('The Bernoulli parameter must be a probability')\n",
    "        self.p = p\n",
    "        \n",
    "    def sample(self):\n",
    "        \"\"\"Returns either 1 or 0 depending on a random simulation\"\"\"\n",
    "        # We rely on numpy's pseudo random number generator to obtain a number uniformly distributed\n",
    "        # between 0 and 1\n",
    "        u = np.random.uniform()\n",
    "        # The idea is to now transform this uniform simulation is such a way that with probability p\n",
    "        #  we get 1 and with probability (1-p) we get a 0\n",
    "        # For example, imagine p = 0.7 then we want to return 1 on average 70% of the times this \n",
    "        #  code is executed. \n",
    "        # Since `u` was uniformly generated, it did not bias any particular segment of the interval \n",
    "        #  between 0 and 1. Therefore if we take the first 70% of that interval to return 1, we \n",
    "        #  simulate the variable correctly. 70% of the interval between 0 and 1 can for example be represented\n",
    "        #  by the interval between 0 and 0.7 (the p parameter) \n",
    "        return 1 if u < self.p else 0\n",
    "    \n",
    "    def sample_n(self, N):\n",
    "        \"\"\"Returns an array of N samples\"\"\"\n",
    "        return np.array([self.sample() for _ in range(N)])\n",
    "    \n",
    "    def pmf(self, value):\n",
    "        \"\"\"\n",
    "        Probability mass function\n",
    "        value: an assignment of X\n",
    "        returns: probability value for X=value\n",
    "        \"\"\"\n",
    "        if value == 1:\n",
    "            return self.p\n",
    "        elif value == 0:\n",
    "            return 1. - self.p\n",
    "        else:\n",
    "            raise ValueError('Bernoully variables can only take on 1 or 0')\n",
    "            \n",
    "    def cdf(self, a):\n",
    "        \"\"\"\n",
    "        Cumulative probability function\n",
    "            F_X(a) = \\sum_{x <= a} P(X=x)\n",
    "        a: an assignment of X\n",
    "        returns: total probability over the interval [-inf, a]\n",
    "        \"\"\"\n",
    "        if a == 0:\n",
    "            return 1. - self.p\n",
    "        elif a == 1:\n",
    "            return 1.\n",
    "        else:\n",
    "            raise ValueError('Bernoully variables can only take on 0 or 1')\n",
    "            \n",
    "    def __repr__(self):\n",
    "        return 'Bernoulli(%s)' % self.p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can declare a Bernoulli random variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X ~ Bernoulli(0.7)\n",
      " P(X=0) = 0.30 F_X(0) = 0.30\n",
      " P(X=1) = 0.70 F_X(1) = 1.00\n"
     ]
    }
   ],
   "source": [
    "X = Bernoulli(0.7)\n",
    "print('X ~', X)\n",
    "for x in range(2):\n",
    "    print(' P(X=%d) = %.2f F_X(%d) = %.2f' % (x, X.pmf(x), x, X.cdf(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that an rv does not give you a value (as normal variables in programming languages would), rvs give you a distribution from which you can sample an assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assignment 0 with probability 0.30\n",
      "assignment 1 with probability 0.70\n",
      "assignment 0 with probability 0.30\n",
      "assignment 0 with probability 0.30\n",
      "assignment 0 with probability 0.30\n",
      "assignment 1 with probability 0.70\n",
      "assignment 0 with probability 0.30\n",
      "assignment 1 with probability 0.70\n",
      "assignment 0 with probability 0.30\n",
      "assignment 0 with probability 0.30\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    x = X.sample()\n",
    "    print('assignment {} with probability {:.2f}'.format(x, X.pmf(x)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can answer some interesting questions about the distribution of a random variable once we get some dataset of observations. \n",
    "So let's get a dataset of `N=1000` Bernoulli variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "bernoulli_observations = X.sample_n(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily plot our samples to get an idea of what we obtained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "_ = plt.hist(bernoulli_observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out the **maximum likelihood estimate** of the Bernoulli parameter is nothing but the ratio in which we observe $X=1$. We can do that rather easily simply by counting the number of 1s and dividing by the total size of the dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bernoulli_mle(observations):\n",
    "    # this is the number of observations we have\n",
    "    N = len(observations)\n",
    "    count1 = observations.sum()\n",
    "    return float(count1) / N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we pretend we do not actually know the Bernoulli parameter, but we have Bernoulli observations, then we can derive a **parameter estimate** that is an educated guess as to what the underlying data generating process actually was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.719"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bernoulli_mle(bernoulli_observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we get something that's quite close to 0.7.\n",
    "\n",
    "That is only the case because we have enough observations. For example, consider estimating the Bernoulli parameter for few examples (as few as `N=10`), you will notice that your estimates are not going to always look good. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt number 0: 0.5\n",
      "Attempt number 1: 0.6\n",
      "Attempt number 2: 0.9\n",
      "Attempt number 3: 0.7\n",
      "Attempt number 4: 0.8\n"
     ]
    }
   ],
   "source": [
    "nb_repetitions = 5\n",
    "for i in range(nb_repetitions):\n",
    "    print('Attempt number {}: {}'.format(i, bernoulli_mle(X.sample_n(10))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex2-9\" style=\"color:red\">**Exercise 2-9**</a> **[3 points]** Compare maximum likelihood estimation for a Bernoulli variable using 1, 10, 100, and 1000 samples. In order to gather enough data, repeat each experiment 100 times. Summarise the results of your investigation using a [boxplot](https://en.wikipedia.org/wiki/Box_plot) for each sample size and provide a discussion on which aspects seem to improve as the sample size grows.\n",
    "\n",
    "Your plot should look like this (give or take some small variance):\n",
    "![Reference for Ex2-9](ex2-9-plot.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Number of repetitions\n",
    "nb_repetitions = 100\n",
    "data = []\n",
    "# loop through number of samples\n",
    "for x in [1, 10, 100, 1000]:\n",
    "    temp_list = []\n",
    "    # loop through number of repetitions\n",
    "    for i in range(nb_repetitions):\n",
    "        # Append the MLE of bernoulli using x (1,10,100,1000) samples\n",
    "        temp_list.append(bernoulli_mle(X.sample_n(x)))\n",
    "    # Append lists of data to data list\n",
    "    data.append(temp_list)\n",
    "\n",
    "# Make boxplot\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.set_xlabel('sample size')\n",
    "ax1.set_ylabel('MLE')\n",
    "ax1.boxplot(data)\n",
    "# Change X-axis to correct labels\n",
    "plt.xticks([1, 2, 3, 4], [1, 10, 100, 1000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex2-10\" style=\"color:red\">**Exercise 2-10**</a> **[10 points]** Now you should extend the Bernoulli case to deal with Categorical random variables, that is \n",
    "\n",
    "1. complete the skeleton class below (2 points in total)\n",
    "    * note this requires completing the sampling procedure (1 point)\n",
    "2. implement the maximum likelihood estimation algorithm (2 points)\n",
    "\n",
    "Also keep in mind that your class is expected to make sure the parameters are *valid* (recall the conditions associated with categorical parameter vectors). \n",
    "\n",
    "To test your representation (1 point):\n",
    "\n",
    "* print the pmf and cdf values for all values the rv can take on (as we did for the Bernoulli example)\n",
    "\n",
    "To test your MLE procedure (3 points): \n",
    "\n",
    "* compute a maximum likelihood estimate using N samples from a Categorical distribution with parameters $[0.1, 0.2, 0.7]$ \n",
    "    * repeat this procedure 1000 times to get the average estimate as well as error estimates: you can get average and error using `np.mean` and `np.std`\n",
    "* plot the average estimate and standard deviation using barplots (with `plt.bar`)\n",
    "    * experiment with N = 1, N = 10, N = 100, and N = 1000\n",
    "* comment on which aspects seem to improve as sample size grows\n",
    "\n",
    "\n",
    "This is all very similar to what was done in the Bernoulli case, but here we replace boxplot by barplots because our Categorical distributions has $k=3$ parameters (not just 1)\n",
    "\n",
    "\n",
    "Hints:\n",
    "\n",
    "* to simulate a categorical random variable you need to generalise the idea shown to you in the case of Bernoulli variables to K segments (rather than 2 segments); in the Bernoulli case we chopped the $[0,1]$ segment into two, namely, $[0, p)$ and $[p, 1]$. If you are not used to the notation $[a,b)$, it means a continuous interval between $a$ (included) and $b$ (excluded), that is, $a \\leq x < b$. Categorical variables defined over K values require K segments chopped like this: $[0, \\theta_1)$, $[\\theta_1, \\theta_1 + \\theta_2)$, $[\\theta_1 + \\theta_2, \\theta_1 + \\theta_2 + \\theta_3)$, and so on till $[\\sum_{i=1}^{K-1} \\theta_i, 1]$. Note how similar this is to the cdf of the categorical variable. \n",
    "* the maximum likelihood estimate of a categorical variable is a vector where each position represents the ratio in which we observe the corresponding value of the random variable, that is `number of time k occurs divided by total number of data points`\n",
    "\n",
    "Important: an alternative way to simulate a categorical variable (which will not be accepted as an aswer to this particular exercise) is to use `np.random.choice` (check its documentation with `np.random.choice?`). \n",
    "\n",
    "Your plot should look like this (give or take some small variance):\n",
    "\n",
    "![Reference for Ex2-10](ex2-10-plot.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we provide you with a sketch that you must complete\n",
    "\n",
    "class Categorical:\n",
    "    \n",
    "    def __init__(self, theta):\n",
    "        \"\"\"\n",
    "            X ~ Categorical(theta_1, ..., theta_K)\n",
    "            where theta is the parameter vector and theta_k is the probability of the kth class\n",
    "            recall that theta_k is bound between 0 and 1 and the sum should be exactly 1\n",
    "        \"\"\"\n",
    "        # Check for valid input\n",
    "        if sum(theta) != 1:\n",
    "            raise ValueError('Probabilities must add up to 1')\n",
    "        for theta_i in theta:\n",
    "            if not (0 <= theta_i <= 1):\n",
    "                raise ValueError('Theta vector must contain probabilities')\n",
    "        # store thetas\n",
    "        self.theta = theta\n",
    "        \n",
    "    def sample(self):\n",
    "        \"\"\"Returns a number from 1 to K representing the sampled value\"\"\"\n",
    "        # get number between 0 and 1\n",
    "        sample = np.random.uniform()\n",
    "        # prepend a 0 to the theta vector\n",
    "        new_theta = [0] + self.theta\n",
    "        for i in range(len(self.theta)):\n",
    "            # check if sample number is between which range, each range corresponding to 1 class\n",
    "            if sum(new_theta[:i+1]) <= sample < sum(new_theta[:i+2]):\n",
    "                # return the class\n",
    "                return i\n",
    "        \n",
    "    def sample_n(self, N):\n",
    "        \"\"\"Returns a numpy array containing N simulated values\"\"\"\n",
    "        # Do self.sample N times\n",
    "        return np.array([self.sample() for _ in range(N)])\n",
    "    \n",
    "    def pmf(self, value):\n",
    "        \"\"\"\n",
    "        Probability mass function evaluated at a certain value\n",
    "        value: an assignment of X\n",
    "        \"\"\"\n",
    "        # loop through range of thetas\n",
    "        for j in range(len(self.theta)):\n",
    "            if value == j:\n",
    "                # return the class' Probability mass\n",
    "                return self.theta[j]\n",
    "        else:\n",
    "            raise ValueError('Not a valid class')\n",
    "    \n",
    "    def cdf(self, a):\n",
    "        \"\"\"\n",
    "        Cumulative probability function\n",
    "            F_X(a) = \\sum_{x <= a} P(X=x)\n",
    "        a: an assignment of X\n",
    "        returns: total probability over the interval [-inf, a]\n",
    "        \"\"\"\n",
    "        # loop through range of thetas\n",
    "        for k in range(len(self.theta)):\n",
    "            if a == k:\n",
    "                # return the Cumulative probability\n",
    "                return sum(self.theta[:k+1])\n",
    "            \n",
    "    def __repr__(self):\n",
    "        # Print object name with thetas\n",
    "        return 'Categorical({})'.format(self.theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_mle(observations, number_classes):\n",
    "    ratio_list = []\n",
    "    # loop through classes\n",
    "    for c in range(number_classes):\n",
    "        N = len(observations)\n",
    "        # count the occurance of each class in observations\n",
    "        count1 = list(observations).count(c)\n",
    "        # Get ratio of class appearance\n",
    "        ratio_list.append(float(count1)/N)\n",
    "    # return list of class appearance ratios\n",
    "    return ratio_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize Categorical object with test thetas\n",
    "Y = Categorical([0.1,0.2,0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y ~ Categorical([0.1, 0.2, 0.7])\n",
      " P(X=0) = 0.10 F_X(0) = 0.10\n",
      " P(X=1) = 0.20 F_X(1) = 0.30\n",
      " P(X=2) = 0.70 F_X(2) = 1.00\n"
     ]
    }
   ],
   "source": [
    "print('Y ~', Y)\n",
    "# Print pmf and cdf values per class\n",
    "for x in range(len(Y.theta)):\n",
    "    print(' P(X=%d) = %.2f F_X(%d) = %.2f' % (x, Y.pmf(x), x, Y.cdf(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 1: means = [0.085 0.204 0.711], stds = [0.2788817  0.40296898 0.45329792]\n",
      "N = 10: means = [0.0977 0.1975 0.7048], stds = [0.08651422 0.1209287  0.13811937]\n",
      "N = 100: means = [0.09914 0.19945 0.70141], stds = [0.02983723 0.03893068 0.04373913]\n",
      "N = 1000: means = [0.099991 0.200166 0.699843], stds = [0.0090646  0.01311779 0.01452977]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb_repetitions = 1000\n",
    "\n",
    "mean_list = []\n",
    "std_list = []\n",
    "N_list = [1, 10, 100, 1000]\n",
    "# Loop through test Ns\n",
    "for x in N_list:\n",
    "    temp_list = []\n",
    "    for i in range(nb_repetitions):\n",
    "        # Get categorical mle of each N samples i times\n",
    "        temp_list.append(categorical_mle(Y.sample_n(x), len(Y.theta)))\n",
    "    # Get mean of ratios per class\n",
    "    mean_list.append(np.mean(np.array(temp_list), axis=0))\n",
    "    # Get standard deviation of ratios per class\n",
    "    std_list.append(np.std(np.array(temp_list), axis=0))\n",
    "\n",
    "# Print stats for each N\n",
    "for xd in range(len(N_list)):\n",
    "    print(f'N = {N_list[xd]}: means = {mean_list[xd]}, stds = {std_list[xd]}')\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "# make barplot of std and mean of each N for each class\n",
    "for i in range(3):\n",
    "    ax.bar(i+0.85, mean_list[0][i], yerr=std_list[0][i], width=0.1, color='r', align='center')\n",
    "    ax.bar(i+0.95, mean_list[1][i], yerr=std_list[1][i], width=0.1, color='b', align='center')\n",
    "    ax.bar(i+1.05, mean_list[2][i], yerr=std_list[2][i], width=0.1, color='g', align='center')\n",
    "    ax.bar(i+1.15, mean_list[3][i], yerr=std_list[3][i], width=0.1, color='y', align='center')\n",
    "plt.ylim(bottom=-0.25, top=1.2)\n",
    "plt.ylabel('MLE')\n",
    "# Change X-axis to correct labels\n",
    "plt.xticks(range(1, len(Y.theta)+1), range(1, len(Y.theta)+1))\n",
    "plt.legend(N_list,loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As N increases the Standard deviation seems to decrease and the results become more stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
