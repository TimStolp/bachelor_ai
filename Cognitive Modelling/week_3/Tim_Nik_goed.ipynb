{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Learning\n",
    "\n",
    "Q-learning algorithmes zijn gebaseerd op de TD-learning modellen die we eerder hebben besproken. Q-learning leert direct de associatie tussen states, actions en outcomes. De robot gaat nu dus niet alleen maar belongingen krijgen maar ook uitzoeken welke handeling de beste is geveven de situatie. \n",
    "\n",
    "Details over Q-learning zijn terug te vinden in de college slides en het hoofdstuk van Gureckis & Love [**computational reinforcement learning**](http://bradlove.org/papers/GureckisLovePress.pdf) en voor meer verdieping in het online boek van [**Sutton & Barto**](http://incompleteideas.net/book/bookdraft2018jan1.pdf) en dan met name hoofdstuk 6.\n",
    "\n",
    "Het leren in deze opdracht speelt zich af in een simpel **Markov Decision Process** met de volgende structuur:\n",
    "\n",
    "![](bandit_arms.png)\n",
    "\n",
    "In deze taak moet de robot telkens uit een van de schatkisten iets pakken. In sommige schatkisten zit meer geld dan in anderen, maar de robot weet in het begin nog niks over de schatkisten, en verwacht er maar weinig van. In elke ronde wordt uitkomst van een schatkist bepaald door een trekking van een waarde uit een normaalverdeling.\n",
    "\n",
    "De uitkomsten van schatkisten verschillen in hun gemiddelde maar niet de variatie (standaard deviatie). \n",
    "\n",
    "**Let op:** In dit simpele experiment is er maar een state, waarin de robot telkens terugkeert na het maken van een keuze. Dit heeft als gevolg dat bij het leren geen rekening gehouden hoeft te worden met de actie in de volgende state gemaakt wordt. De standaard prediction-error:\n",
    "\n",
    "$$\\delta = r_{t+1} + \\gamma\\ max_a\\ Q(s_{t+1} , a) − Q(s_t , a_t)$$\n",
    "\n",
    "verandert dus simpelweg in:\n",
    "$$\\delta = r_{t+1} − Q(s_t , a_t)$$\n",
    "\n",
    "In het begin van het experiment heeft de robot geen enkele kennis van de wereld en geen enkele verwachtingen voor van het krijgen van beloningen. Voor elke schatkist geldt:\n",
    "\n",
    "$$Q(1)=Q(2)=Q(3)=Q(4)=0$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.a (5 punten)\n",
    "\n",
    "Schrijf de Q-learning functie op die de nieuwe waarde Q uitrekent nadat de robot een schatkist heeft uitgekozen. Welke vrije variabele heeft deze functie en wat is zijn rol in leren? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">$Q(x) = Q(x) + \\alpha*(r_{t+1} - Q(x))$\n",
    "\n",
    ">$\\alpha$ is de vrije variabele, deze vari\\\"eren verandert de snelheid waarmee de agent leert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.b (5 punten)\n",
    "\n",
    "Stel de robot selecteert schatkist 1 en vindt twee munten. Wat is hierna de waarde van Q(1)? rapporteer dit voor\n",
    "$\\alpha=0.5$ en $\\alpha=0.2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">$\\alpha = 0.5: Q(1) = 0 + 0.5*(2 - 0) = 1$\n",
    "\n",
    ">$\\alpha = 0.2: Q(1) = 0 + 0.2*(2 - 0) = 0.4$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.c (10 punten)\n",
    "\n",
    "Schrijf een functie `q_learn` die als input, alpha ($\\alpha$), epsilon($\\epsilon$) en rondes (trials) accepteert. De output van deze functie moet een lijst met $Q$ waarden zijn voor elke schatkist (1 t/m 4) in de wereld van de robot na het leren van een aantal rondes. We gaan er nu van uit dat de robot de $\\epsilon$-greedy keuze regel toepast.\n",
    "\n",
    "* Initieer de verwachtingen van de robot voor de 4 keuzes:\n",
    "    * Q(1)=Q(2)=Q(3)=Q(4)=0. \n",
    "* Intieer total_score = 0\n",
    "* Initieer de beloningen voor de 4 schatkisten:\n",
    "    * K(1): mean=20, SD=4\n",
    "    * K(2): mean=30, SD=4\n",
    "    * K(3): mean=50, SD=4\n",
    "    * K(4): mean=70, SD=4\n",
    "* Creëer een for-loop over alle rondes:\n",
    "    * Elke ronde selecteert de robot een kist op basis van $\\epsilon$-greedy. Denk er aan bij explore een random kist, bij exploit de kist met hoogste Q-value (als er meerdere de hoogste waarde hebben, daar weer random uit kiezen). \n",
    "    * Kijk wat de beloning is na maken van een keuze, en update dan Q-value van die kist. \n",
    "* zorg dat deze functie de volgende lijsten als output heeft: final Q values, total_score, en voor elke schatkist een lijst wanneer deze gekozen werd (1 voor gekozen een 0 wanneer niet gekozen). Dit resulteert in 4 lijsten met keuzes die gebruikt kunnen worden voor het plotten van het gedrag van het model.\n",
    "\n",
    "\n",
    "Laat me behulp van deze functie de robot 200 rondes leren over deze wereld (1 leer episode bestaat dus uit 200 rondes). Hoe zien zijn verwachtingen (Q-values) voor de schatkisten aan het eind van het experiment er uit gegeven\n",
    "\n",
    "1. $\\alpha = 0.1$ en $\\epsilon = 0.1$\n",
    "2. $\\alpha = 0.5$ en $\\epsilon = 0.1$\n",
    "\n",
    "Laat voor beide modellen zien wat de totale verdiende score is gedurende de trails, wat de geleede Q-values zijn voor elke kist en plot hoe de keuzes voor de verschillende kisten veranderen gedurende de trails.\n",
    "\n",
    "Voor het plotten van keuzes is het handig om naar het gemiddels van bins van 10 trails tegelijk te kijken. Alvast wat code om je beetje op weg te helpen:\n",
    "```python\n",
    "# Width is de grote van elke bin\n",
    "width = 10\n",
    "# Hier knippen we de laatste (choicelist_1.size % width) elementen van de lijst\n",
    "# Dan reshapen we naar een matrix van X * width en nemen we de mean over de width axis\n",
    "# Hiermee krijgen we dus het gemiddelde aantal keer dat deze keuze gemaakt is voor width stappen\n",
    "result1 = choicelist_1[:(choicelist_1.size // width * width)].reshape(-1, width).mean(axis=1)\n",
    "plt.plot(result1, label=r\"$1$\")\n",
    "```\n",
    "\n",
    "Welk van de twee geleerde modellen zit dichter bij de waarheid op basis van deze resultaten?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21.322751906296446, 11.711444788253843, 13.511592758606, 69.86812384293881]\n",
      "[19.749753498869186, 18.13731459495658, 51.93864094101862, 0]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def q_learn(alpha, epsilon, trials):\n",
    "    Q1 = 0\n",
    "    Q2 = 0\n",
    "    Q3 = 0\n",
    "    Q4 = 0\n",
    "    Q1_list = np.zeros(trials)\n",
    "    Q2_list = np.zeros(trials)\n",
    "    Q3_list = np.zeros(trials)\n",
    "    Q4_list = np.zeros(trials)\n",
    "    K1 = 20\n",
    "    K2 = 30\n",
    "    K3 = 50\n",
    "    K4 = 70\n",
    "    sigma = 4\n",
    "    total_score = 0\n",
    "    \n",
    "    for i in range(trials):\n",
    "        x = random.random()\n",
    "        \n",
    "        if x < epsilon:            \n",
    "            ind = random.randrange(len([Q1, Q2, Q3, Q4]))\n",
    "        else:\n",
    "            ind = np.argmax([Q1, Q2, Q3, Q4])\n",
    "         \n",
    "        if ind == 0:\n",
    "            s = np.random.normal(K1, sigma)\n",
    "            Q1 += alpha*(s - Q1)\n",
    "            Q1_list[i] = 1\n",
    "        elif ind == 1:\n",
    "            s = np.random.normal(K2, sigma)\n",
    "            Q2 += alpha*(s - Q2)\n",
    "            Q2_list[i] = 1\n",
    "        elif ind == 2:\n",
    "            s = np.random.normal(K3, sigma)\n",
    "            Q3 += alpha*(s - Q3)\n",
    "            Q3_list[i] = 1\n",
    "        else:\n",
    "            s = np.random.normal(K4, sigma)\n",
    "            Q4 += alpha*(s - Q4)\n",
    "            Q4_list[i] = 1\n",
    "        \n",
    "        total_score += s\n",
    "            \n",
    "    return([Q1,Q2,Q3,Q4], total_score, [Q1_list, Q2_list, Q3_list, Q4_list])\n",
    "\n",
    "\n",
    "[Q_list1, _, _] = q_learn(0.1, 0.1, 200)\n",
    "[Q_list5, _, _] = q_learn(0.5, 0.1, 200)\n",
    "print(Q_list1)\n",
    "print(Q_list5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Het model met $\\alpha = 0.5$ zit dichterbij de waarheid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f32a06f1ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3298113da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learnt_scores, total_score, [choicelist_1, choicelist_2, choicelist_3, choicelist_4] = q_learn(0.1,0.1,200)\n",
    "\n",
    "# Width is de grote van elke bin\n",
    "width = 10\n",
    "# Hier knippen we de laatste (choicelist_1.size % width) elementen van de lijst\n",
    "# Dan reshapen we naar een matrix van X * width en nemen we de mean over de width axis\n",
    "# Hiermee krijgen we dus het gemiddelde aantal keer dat deze keuze gemaakt is voor width stappen\n",
    "result1 = choicelist_1[:(choicelist_1.size // width * width)].reshape(-1, width).mean(axis=1)\n",
    "result2 = choicelist_2[:(choicelist_2.size // width * width)].reshape(-1, width).mean(axis=1)\n",
    "result3 = choicelist_3[:(choicelist_3.size // width * width)].reshape(-1, width).mean(axis=1)\n",
    "result4 = choicelist_4[:(choicelist_4.size // width * width)].reshape(-1, width).mean(axis=1)\n",
    "plt.plot(result1, label=r\"$1$\")\n",
    "plt.plot(result2, label=r\"$1$\")\n",
    "plt.plot(result3, label=r\"$1$\")\n",
    "plt.plot(result4, label=r\"$1$\")\n",
    "plt.show()\n",
    "\n",
    "learnt_scores, total_score, [choicelist_1, choicelist_2, choicelist_3, choicelist_4] = q_learn(0.5,0.1,200)\n",
    "\n",
    "result1 = choicelist_1[:(choicelist_1.size // width * width)].reshape(-1, width).mean(axis=1)\n",
    "result2 = choicelist_2[:(choicelist_2.size // width * width)].reshape(-1, width).mean(axis=1)\n",
    "result3 = choicelist_3[:(choicelist_3.size // width * width)].reshape(-1, width).mean(axis=1)\n",
    "result4 = choicelist_4[:(choicelist_4.size // width * width)].reshape(-1, width).mean(axis=1)\n",
    "plt.plot(result1, label=r\"$1$\")\n",
    "plt.plot(result2, label=r\"$1$\")\n",
    "plt.plot(result3, label=r\"$1$\")\n",
    "plt.plot(result4, label=r\"$1$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.d (10 punten)\n",
    "\n",
    "Laten we nu kijken hoe succesvol de verschillende strategieën (lees combinatie van parameter waardes) zijn. \n",
    "\n",
    "Schrijf nu een loop die `q_learn` 500 keer aanroept met een bepaalde parameter setting (en altijd 200 leerrondes) en sla telkens het totaal aantal punten op, zodat je aan het eind een lijst hebt van 500 totaal scores. \n",
    "\n",
    "Vergelijk het gemiddelde van die 500 totaalscores voor $\\alpha=0.1$, $\\alpha=0.3$ en $\\alpha=0.5$ met $\\epsilon=0.1$ voor alle experimenten. Leg uit hoe de verschillen tot stand komen. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha 0.1 mean total score = 8432.818469466743\n",
      "alpha 0.3 mean total score = 11451.773833014775\n",
      "alpha 0.5 mean total score = 11924.135016932356\n"
     ]
    }
   ],
   "source": [
    "score_list1 = []\n",
    "score_list3 = []\n",
    "score_list5 = []\n",
    "ep = 500\n",
    "\n",
    "for i in range(ep):\n",
    "    [_, total_score1, _] = q_learn(0.1, 0.1, 200)\n",
    "    score_list1.append(total_score1)\n",
    "    \n",
    "    [_, total_score3, _] = q_learn(0.3, 0.1, 200)\n",
    "    score_list3.append(total_score3)\n",
    "    \n",
    "    [_, total_score5, _] = q_learn(0.5, 0.1, 200)\n",
    "    score_list5.append(total_score5)\n",
    "    \n",
    "print(f\"alpha 0.1 mean total score = {np.mean(score_list1)}\")\n",
    "print(f\"alpha 0.3 mean total score = {np.mean(score_list3)}\")\n",
    "print(f\"alpha 0.5 mean total score = {np.mean(score_list5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Een hogere $\\alpha$-waarde zorgt ervoor dat de agent uit het model sneller leert van de uitkomsten van de kisten. Dit verkleint de kans dat de agent een hogere value krijgt voor bijvoorbeeld Q1 dan voor Q2, als het door de willekeurigheid van de waarde uit de normaalverdeling een bepaalde mening vormt over deze kisten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration-Exploitation\n",
    "\n",
    "We gaan nu dieper in op het exploration vs. exploitation dilemma. Laten we eerst kijken hoe verschillende e parameters uitwerking hebben op het aantal punten dat gewonnen wordt. Gebruik hier de functie van q_learn van de vorige vraag met $\\epsilon=0.05$, $\\epsilon=0.2$ en $\\epsilon=0.6$ en met $\\alpha=0.3$ voor alle experimenten. \n",
    "\n",
    "### Q2.a (10 punten)\n",
    "\n",
    "Kijk voor elke parameter setting weer naar de gemiddelde totaal score van 500 leer episodes. Waar ligt ongeveer het optimale niveau van exploratie?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon 0.05 mean total score = 10407.42850187573\n",
      "Epsilon 0.2 mean total score = 11938.451203146231\n",
      "Epsilon 0.6 mean total score = 10515.17902026963\n"
     ]
    }
   ],
   "source": [
    "e_list = [0.05, 0.2, 0.6]\n",
    "alpha = 0.3\n",
    "trials = 200\n",
    "ep = 500\n",
    "\n",
    "for epsilon in e_list:\n",
    "    score_list = []\n",
    "    for i in range(ep):\n",
    "        [_, total_score, _] = q_learn(alpha, epsilon, trials)\n",
    "        score_list.append(total_score)\n",
    "    print(f\"Epsilon {epsilon} mean total score = {np.mean(score_list)}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Met een $\\epsilon$-waarde van 0.2 wordt de hoogste totaalscore behaald."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.b (10 punten)\n",
    "\n",
    "Pas nu `q_learn` zo aan dat de parameter $\\epsilon$ gedurende een leer episode steeds kleiner wordt. Dit kan bijvoorbeeld door elke ronde $\\epsilon$ met een vast percentage te verkleinen (denk aan iets tussen 0 en 10%), maar andere manieren zijn ook mogelijk. Sla dit model op als `q_learn_decay`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_learn_decay(alpha, epsilon, trials=200):\n",
    "    Q1 = 0\n",
    "    Q2 = 0\n",
    "    Q3 = 0\n",
    "    Q4 = 0\n",
    "    Q1_list = np.zeros(trials)\n",
    "    Q2_list = np.zeros(trials)\n",
    "    Q3_list = np.zeros(trials)\n",
    "    Q4_list = np.zeros(trials)\n",
    "    K1 = 20\n",
    "    K2 = 30\n",
    "    K3 = 50\n",
    "    K4 = 70\n",
    "    sigma = 4\n",
    "    total_score = 0\n",
    "    decay = 0.01\n",
    "    \n",
    "    for i in range(trials):\n",
    "        x = random.random()\n",
    "        \n",
    "        if x < epsilon:            \n",
    "            ind = random.randrange(len([Q1, Q2, Q3, Q4]))\n",
    "        else:\n",
    "            ind = np.argmax([Q1, Q2, Q3, Q4])\n",
    "         \n",
    "        if ind == 0:\n",
    "            s = np.random.normal(K1, sigma)\n",
    "            Q1 += alpha*(s - Q1)\n",
    "            Q1_list[i] = 1\n",
    "        elif ind == 1:\n",
    "            s = np.random.normal(K2, sigma)\n",
    "            Q2 += alpha*(s - Q2)\n",
    "            Q2_list[i] = 1\n",
    "        elif ind == 2:\n",
    "            s = np.random.normal(K3, sigma)\n",
    "            Q3 += alpha*(s - Q3)\n",
    "            Q3_list[i] = 1\n",
    "        else:\n",
    "            s = np.random.normal(K4, sigma)\n",
    "            Q4 += alpha*(s - Q4)\n",
    "            Q4_list[i] = 1\n",
    "        \n",
    "        total_score += s\n",
    "        epsilon *= (1 - decay)\n",
    "            \n",
    "    return([Q1,Q2,Q3,Q4], total_score, [Q1_list, Q2_list, Q3_list, Q4_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.c (10 punten)\n",
    "\n",
    "Kijk nu naar een aantal beginwaarden voor parameter $\\epsilon$, en kijk welk model meer punten kan verdienen in de taak (verken hier waarden van $\\epsilon$ tussen .1 en .9). Gebruik weer het gemiddelde aantal punten over 500 leer episodes (en nog steeds 200 rondes per episode en $\\alpha =  0.3$). Welk model is het beste en waarom denk je dat dit zo is?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon 0.1 mean total score = 11000.569963160984\n",
      "Epsilon 0.2 mean total score = 11955.12898428746\n",
      "Epsilon 0.3 mean total score = 12400.600458790455\n",
      "Epsilon 0.4 mean total score = 12448.555341380075\n",
      "Epsilon 0.5 mean total score = 12474.847579536545\n",
      "Epsilon 0.6 mean total score = 12343.932251486332\n",
      "Epsilon 0.7 mean total score = 12181.812052098696\n",
      "Epsilon 0.8 mean total score = 11989.131471481818\n",
      "Epsilon 0.9 mean total score = 11820.744119546875\n"
     ]
    }
   ],
   "source": [
    "ep_list = list(range(1,10))\n",
    "epList = [x / 10 for x in ep_list]\n",
    "alpha = 0.3\n",
    "trials = 200\n",
    "ep = 500\n",
    "\n",
    "for epsilon in epList:\n",
    "    score_list = []\n",
    "    for i in range(ep):\n",
    "        [_, total_score, _] = q_learn_decay(alpha, epsilon, trials)\n",
    "        score_list.append(total_score)\n",
    "    print(f\"Epsilon {epsilon} mean total score = {np.mean(score_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> De hoogste totaalscores liggen zowel bij $\\epsilon$-startwaardes van 0.4 als 0.5. Een $\\epsilon$-startwaarde van rond de 0.5 zorgt ervoor dat het model genoeg exploreert aan het begin, ten opzichte van lagere waardes als 0.1, terwijl het later ook zijn Q-waardes genoeg verifi\\\"eert, door Qmax te bekijken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax\n",
    "\n",
    "Een andere zeer populaire methode om exploratie te implementeren is de softmax regel. Deze kan gebruikt worden om de waarschijnlijkheid uit te rekenen dat de robot een specifieke kist kiest. Bijvoorbeeld de waarschijnlijkheid dat de robot op een bepaald moment kist 1 kiest is:\n",
    "\n",
    "$$P(Q(1)) = \\frac{e(Q(1)*theta)}{\\sum_s e(Q(s)*theta)}$$\n",
    "\n",
    "Voor kist 2:\n",
    "\n",
    "$$P(Q(2)) = \\frac{e(Q(2)*theta)}{\\sum_s e(Q(s)*theta)}$$\n",
    "\n",
    "En natuurlijk:\n",
    "\n",
    "$$P(Q(1))+ P(Q(2)) +P(Q(3))+ P(Q(2)) = 1  (100\\%)$$\n",
    "\n",
    "want de robot kiest altijd een van de 4 opties, dus samen moeten dat 100% kans zijn.\n",
    "\n",
    "Implementeer nu de softmax regel in de `q_learn` functie en geef deze de naam `q_learn_softmax`.\n",
    "\n",
    "* Gebruik elke ronde de $P(Q)$ informatie om de robot een kist te laten kiezen.\n",
    "* Zorg ook dat deze elke ronde de waarschijnlijkheid $P(Q)$ van het kiezen van elke kist wordt opgeslagen zodat we hier later weer naar kunnen kijken. \n",
    "\n",
    "Gebruik dit model weer om de gemiddelde score voor 500 episodes voor verschillende waardes van theta (waardes tussen $0.01$ en $1$, op zn minst 5) met elkaar te vergelijken, met wederom 200 rondes per episode en een $\\alpha$ van $0.3$, gebruik makende van de methode die we hier boven ontwikkeld hebben. \n",
    "\n",
    "\n",
    "### Q3.a (10 punten)\n",
    "\n",
    "Wat is ongeveer de optimale waarde voor theta, hoe verhoud dit model zich tot de simpele versie van $\\epsilon$-greedy? Hoe gedraagt het model zicht met een hoge waarde van theta, en hoe met een lage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta 0.01 total score = 9208.89945515291\n",
      "Theta 0.12 total score = 12334.787996571426\n",
      "Theta 0.23 total score = 10828.326878731326\n",
      "Theta 0.34 total score = 9868.118563592338\n",
      "Theta 0.45 total score = 8908.408397573761\n",
      "Theta 0.56 total score = 8754.150527943548\n",
      "Theta 0.67 total score = 8521.558884913651\n",
      "Theta 0.78 total score = 8568.116495783564\n",
      "Theta 0.89 total score = 8667.525343782176\n",
      "Theta 1.0 total score = 8533.719069889843\n"
     ]
    }
   ],
   "source": [
    "def softmax(q_list, theta):\n",
    "    q_list = np.array(q_list)\n",
    "    p_list = []\n",
    "    for i in range(len(q_list)):\n",
    "        p_list.append(np.exp(q_list[i]*theta)/sum(np.exp(q_list*theta)))\n",
    "    return p_list\n",
    "    \n",
    "\n",
    "def q_learn_softmax(alpha, trials, theta):\n",
    "    Q1 = 0\n",
    "    Q2 = 0\n",
    "    Q3 = 0\n",
    "    Q4 = 0\n",
    "    Q1_list = np.zeros(trials)\n",
    "    Q2_list = np.zeros(trials)\n",
    "    Q3_list = np.zeros(trials)\n",
    "    Q4_list = np.zeros(trials)\n",
    "    K1 = 20\n",
    "    K2 = 30\n",
    "    K3 = 50\n",
    "    K4 = 70\n",
    "    sigma = 4\n",
    "    total_score = 0\n",
    "    \n",
    "    for i in range(trials):\n",
    "        \n",
    "        ind = np.random.choice(4, p=softmax([Q1, Q2, Q3, Q4], theta))\n",
    "         \n",
    "        if ind == 0:\n",
    "            s = np.random.normal(K1, sigma)\n",
    "            Q1 += alpha*(s - Q1)\n",
    "            Q1_list[i] = 1\n",
    "        elif ind == 1:\n",
    "            s = np.random.normal(K2, sigma)\n",
    "            Q2 += alpha*(s - Q2)\n",
    "            Q2_list[i] = 1\n",
    "        elif ind == 2:\n",
    "            s = np.random.normal(K3, sigma)\n",
    "            Q3 += alpha*(s - Q3)\n",
    "            Q3_list[i] = 1\n",
    "        else:\n",
    "            s = np.random.normal(K4, sigma)\n",
    "            Q4 += alpha*(s - Q4)\n",
    "            Q4_list[i] = 1\n",
    "        \n",
    "        total_score += s\n",
    "            \n",
    "    return([Q1,Q2,Q3,Q4], total_score, [Q1_list, Q2_list, Q3_list, Q4_list])\n",
    "\n",
    "t_list = np.linspace(0.01, 1, 10)\n",
    "alpha = 0.3\n",
    "trials = 200\n",
    "ep = 500\n",
    "\n",
    "for theta in t_list:\n",
    "    score_list = []\n",
    "    for i in range(ep):\n",
    "        [_, total_score, _] = q_learn_softmax(alpha, trials, theta)\n",
    "        score_list.append(total_score)\n",
    "    print(f\"Theta {theta} total score = {np.mean(score_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Het model vertoont dezelfde kenmerken als het $\\epsilon$-greedy model. De hoogste waarde van total_score komt vroeg, namelijk rond een $\\theta$-waarde van 0.12, waar het maximum van $\\epsilon$-greedy lag rond een waarde van 0.2. De totaalscore wordt lager naarmate de $\\theta$-waarde voorbij 0.12 komt en neemt vanaf dit punt tot $\\epsilon$ = 0.5 geleidelijk af, waarna de waarde ongeveer hetzelfde blijft."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fitting\n",
    "\n",
    "We gaan nu kijken naar de resultaten van een echt experiment. We hebben de data van een proefpersoon die het bovenstaande experiment heeft gespeeld. In de data file kunnen we terugvinden welke van de 4 opties zij gekozen had en hoeveel punten vervolgens elke trial verdient zijn. We gaan kijken met welke parameter waardes  Q-learning met een softmax choice rule het gedrag van de proefpersonen het beste kan voorspellen. De proefpersoon heeft 80 rondes gespeelt. \n",
    "\n",
    "Lees de data in uit *L4_data_1.txt* met behulp van [loadtxt](https://docs.scipy.org/doc/numpy/reference/generated/numpy.loadtxt.html):\n",
    "```python\n",
    "with open(\"L4_data_1.txt\") as f:\n",
    "    data = np.loadtxt(f, dtype=int, delimiter=\"\\t\", skiprows=1)\n",
    "```\n",
    "\n",
    "Pas de `q_learn_softmax` functie aan zodat je deze op de data van de proefpersonen kan fitten. (Zie LC1 voor details over hoe functies gefit moeten worden, en pseudo code onderaan voor meer hulp).\n",
    "\n",
    "Ga er van uit dat de proefpersonen enige ervaring hebben met dit type experiment en verwachten dat ze gemiddeld wel 40 punten per ronde gaan verdienen (alle Q’s starten op 40 ipv 0). \n",
    "\n",
    "We gaan voor het fitten van het model gebruik maken van minimize van scipy.optimize (`from scipy.optimize import minimize`) en we gaan proberen *Log Likelihood* te optimaliseren (mate van fit). \n",
    "\n",
    "Wat we op elke trial willen weten is wat de waarschijnlijkheid is dat het model dezelfde keuze maakte als de proefpersoon. Hoe groter de kans (likelihood) dat het model correct kiest, hoe beter het model \"fit\". \n",
    "\n",
    "In het databestand van de proefpersoon kunnen zien welke van de 4 kisten de proefpersoon koos. Dit kunnen we dan op elke ronde vergelijken met de corresponderende P(Q). In de eerste ronde zijn alle Q values nog gelijk dus zijn alle P(Q)s = .25.\n",
    "\n",
    "Voor de eerste ronde geld daarom automatisch dan waarschijnlijkheid (likelihood) van de keuze van de proefpersoon ook .25 is, maar dat gaat veranderen naarmate er geleerd wordt. \n",
    "\n",
    "In het databestand staat ook voor elke ronde wat de uitkomst van een keuze was, deze moet gebruikt worden om vervolgens de Q-values aan te passen, net als we eerder gedaan hebben in de simulaties.\n",
    "\n",
    "De output van deze functie moet de som van alle *log(P(Q(chosen)))* zijn. Let op vermenigvuldig deze som met -1. Dat doen we omdat minimize de functie probeert te minimaliseren , en we opzoek zijn naar de max LL (double negative). \n",
    "\n",
    "`**pseudo code**:`\n",
    "```python\n",
    "def q_learn_softmax_fit(params):\n",
    "    alpha, theta, init_value = params\n",
    "    nArms = 4\n",
    "    Q = np.array([init_value]*nArms)\n",
    "    LL = 0\n",
    "    \n",
    "    for row in data:\n",
    "        probs <- calculate probability of chosing each option based on theta, Qvalues and softmax\n",
    "        \n",
    "        choice <- read choice from data (each trial is one row in file)\n",
    "        outcome <- read outcomee of choice from data\n",
    "        \n",
    "        LL += np.log(probs[choice])\n",
    "        \n",
    "        Q[choice] <- update Q value\n",
    "    \n",
    "    # Scaled for minimize function\n",
    "    return -1*LL\n",
    "\n",
    "# minimize takes a few arguments (function, array of initial parameter values, minimization methods,\n",
    "# bounds are the bounds on each parameter; use bounds (same, same) to fix parameter to a single value\n",
    "res = minimize(q_learn_softmax_fit, np.array([0.5, 0.5, 40]), method='SLSQP',\n",
    "               bounds=[(0,1), (0,10), (40,40)], options={'disp':True, 'ftol':1e-16})\n",
    "```\n",
    "\n",
    "### Q4.a (10 punten)\n",
    "\n",
    "Welke parameterwaarden fitten de data van de proefpersoon het beste? Probeer eens een hogere start waarde voor Q values (>80) en hoe beïnvloed dit de model fit? \n",
    "minimize geeft ook de uiteindelijke summed LL (negatief) van het best fittende model. Deze score kan je weer omrekenen naar een gemiddelde likelihood (kans dat model juiste trial koos) per trial. Doe dit, een beoordeel de uitkomst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startwaarde Q = 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 56.081857619579395\n",
      "            Iterations: 12\n",
      "            Function evaluations: 80\n",
      "            Gradient evaluations: 12\n",
      "de parameters [ 0.48925202  0.23180105 40.        ] fitten de persoon het best\n",
      "de gemiddelde likelihood = 0.49607744752404526\n",
      "\n",
      "\n",
      "startwaarde Q = 100\n",
      "Positive directional derivative for linesearch    (Exit mode 8)\n",
      "            Current function value: 110.90354888959129\n",
      "            Iterations: 7\n",
      "            Function evaluations: 15\n",
      "            Gradient evaluations: 3\n",
      "de parameters [  0.99999892   0.         100.        ] fitten de persoon het best\n",
      "de gemiddelde likelihood = 0.24999999999999983\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def q_learn_softmax_fit(params):\n",
    "    alpha, theta, init_value = params\n",
    "    \n",
    "    with open(\"L4_data_1.txt\") as f:\n",
    "        data = np.loadtxt(f, dtype=int, delimiter=\"\\t\", skiprows=1)\n",
    "    \n",
    "    nArms = 4\n",
    "    Q = np.array([init_value]*nArms)\n",
    "    LL = 0\n",
    "\n",
    "    for row in data:\n",
    "        probs = softmax(Q, theta)\n",
    "\n",
    "        choice = row[1] - 1\n",
    "        outcome = row[2]\n",
    "\n",
    "        LL += np.log(probs[choice])\n",
    "\n",
    "        Q[choice] += alpha*(outcome - Q[choice])\n",
    "\n",
    "    # Scaled for minimize function\n",
    "    return -1*LL\n",
    "\n",
    "with open(\"L4_data_1.txt\") as f:\n",
    "    data = np.loadtxt(f, dtype=int, delimiter=\"\\t\", skiprows=1)\n",
    "    \n",
    "print(\"startwaarde Q = 40\")\n",
    "res = minimize(q_learn_softmax_fit, np.array([0.5, 0.5, 40]), method='SLSQP',\n",
    "               bounds=[(0,1), (0,10), (40,40)], options={'disp':True, 'ftol':1e-16})\n",
    "\n",
    "print(f\"de parameters {res.x} fitten de persoon het best\")\n",
    "print(f\"de gemiddelde likelihood = {np.exp(-1*res.fun/len(data))}\\n\\n\")\n",
    "\n",
    "print(\"startwaarde Q = 100\")\n",
    "res = minimize(q_learn_softmax_fit, np.array([0.5, 0.5, 100]), method='SLSQP',\n",
    "               bounds=[(0,1), (0,10), (100,100)], options={'disp':True, 'ftol':1e-16})\n",
    "\n",
    "print(f\"de parameters {res.x} fitten de persoon het best\")\n",
    "print(f\"de gemiddelde likelihood = {np.exp(-1*res.fun/len(data))}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Het best fittende model van een Q-startwaarde van 40 ligt bij een $\\alpha$-waarde van rond de 0.5, en een $\\theta$-waarde van 0.23. Als de Q-startwaarde verhoogd wordt naar 100, nadert de optimale $\\alpha$-waarde de 1, en de $\\theta$ de 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4.b (10 punten)\n",
    "\n",
    "Herschrijf de functie nogmaals en zorg ervoor dat de initialisatie van de Q waarde (de start Q waarden) ook een vrije parameter wordt. Als je dit doet kan je de start waarde vinden die het best bij het gedrag van de proefpersoon past. Rapporteer, en interpreteer deze waarde. En zorgt dit ook voor een betere model fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 26.010035104746027\n",
      "            Iterations: 19\n",
      "            Function evaluations: 113\n",
      "            Gradient evaluations: 19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.57894821,  0.25470942, 24.07207659])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = minimize(q_learn_softmax_fit, np.array([0.5, 0.5, 40]), method='SLSQP',\n",
    "               bounds=[(0,1), (0,10), (0,10000)], options={'disp':True, 'ftol':1e-16})\n",
    "\n",
    "res.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Het variable maken van de Q startwaarden zorgt voor een uiteindelijke startwaarde van 24.07 wat lijkt op de 25% kans dat een kist wordt gekozen in het begin. Het heeft ook gezorgd voor een veel hogere gemiddelde likelihood. Het heeft er dus voor gezorgd dat de fit beter is geworden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4.c (10 punten)\n",
    "\n",
    "Als we de functie een klein beetje herschrijven kunnen we deze gebruiken om in het hoofd van de proefpersoon te kijken. Bijvoorbeeld we willen nu weten welke Q-values zij aan de verschillende bandits toekent. \n",
    "\n",
    "Hiervoor is alleen een kleine verandering nodig, waarbij de functie nu niet meer de LogLikelihood als output heeft maar de lijst met Q values. Pas de functie `q_learn_softmax_fit` aan zodat deze de Q-values returnt en noem de nieuwe functie `q_learn_fitted_model`. Zorg hierbij dat de `params` lijst van argumenten ook hetzelfde blijft als bij de `q_learn_softmax_fit`.\n",
    "\n",
    "Nu hoef je ook niet meer de functie fitten of minimalizeren maar alleen aan te roepen, gebruik makende van de beste gevonden `params` van de vorige stap.\n",
    "\n",
    "`q_learn_fitted_model(res.x)`\n",
    "\n",
    "Rapporteer de Q values van deze proefpersoon. In werkelijkheid waren de gemiddelde waardes van den bandits (50, 30, 20, 80). Hoe wijkt de proefpersoon hier van af en hoe is dat te verklaren (hint: kijk naar keuze gedrag, dus de selectie van bandits, in de data file)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_learn_fitted_model(params):\n",
    "    alpha, theta, init_value = params\n",
    "    \n",
    "    with open(\"L4_data_1.txt\") as f:\n",
    "        data = np.loadtxt(f, dtype=int, delimiter=\"\\t\", skiprows=1)\n",
    "    \n",
    "    nArms = 4\n",
    "    Q = np.array([init_value]*nArms)\n",
    "\n",
    "    for row in data:\n",
    "        probs = softmax(Q, theta)\n",
    "\n",
    "        choice = row[1] - 1\n",
    "        outcome = row[2]\n",
    "\n",
    "\n",
    "        Q[choice] += alpha*(outcome - Q[choice])\n",
    "\n",
    "    # Scaled for minimize function\n",
    "    return Q\n",
    "\n",
    "q_learn_fitted_model(res.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> De waardes van bandits 1 en 4 lijken sterk op de echte waardes terwijl bandits 2 en 3 meer afwijken. Dit komt doordat de proefpersoon heel weinig bandits 2 en 3 kiest en wel vaak bandits 1 en 4 waardoor de Q waarde van 1 en 4 wel wordt geupdate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
